{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facd7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "importing Jupyter notebook from driving_data_new.ipynb\n",
      "importing Jupyter notebook from model.ipynb\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import import_ipynb\n",
    "import driving_data_new\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e23bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c6db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5023b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2NormConst = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba08a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1758370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3648732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa916b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2918c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85c761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55d20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7fa8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 6.29895\n",
      "Epoch: 0, Step: 10, Loss: 6.37607\n",
      "Epoch: 0, Step: 20, Loss: 6.44906\n",
      "Epoch: 0, Step: 30, Loss: 6.25885\n",
      "Epoch: 0, Step: 40, Loss: 6.18236\n",
      "Epoch: 0, Step: 50, Loss: 6.05436\n",
      "Epoch: 0, Step: 60, Loss: 6.04507\n",
      "Epoch: 0, Step: 70, Loss: 5.77935\n",
      "Epoch: 0, Step: 80, Loss: 5.83152\n",
      "Epoch: 0, Step: 90, Loss: 5.97141\n",
      "Epoch: 0, Step: 100, Loss: 5.74603\n",
      "Epoch: 0, Step: 110, Loss: 5.53378\n",
      "Epoch: 0, Step: 120, Loss: 5.57288\n",
      "Epoch: 0, Step: 130, Loss: 5.42585\n",
      "Epoch: 0, Step: 140, Loss: 5.3072\n",
      "Epoch: 0, Step: 150, Loss: 5.51574\n",
      "Epoch: 0, Step: 160, Loss: 5.43737\n",
      "Epoch: 0, Step: 170, Loss: 5.25247\n",
      "Epoch: 0, Step: 180, Loss: 5.23586\n",
      "Epoch: 0, Step: 190, Loss: 5.18608\n",
      "Epoch: 0, Step: 200, Loss: 4.88373\n",
      "Epoch: 0, Step: 210, Loss: 5.09755\n",
      "Epoch: 0, Step: 220, Loss: 5.32081\n",
      "Epoch: 0, Step: 230, Loss: 5.00313\n",
      "Epoch: 0, Step: 240, Loss: 4.81133\n",
      "Epoch: 0, Step: 250, Loss: 4.93885\n",
      "Epoch: 0, Step: 260, Loss: 4.59636\n",
      "Epoch: 0, Step: 270, Loss: 4.82327\n",
      "Epoch: 0, Step: 280, Loss: 4.53311\n",
      "Epoch: 0, Step: 290, Loss: 4.46298\n",
      "Epoch: 0, Step: 300, Loss: 4.50073\n",
      "Epoch: 0, Step: 310, Loss: 4.4176\n",
      "Epoch: 0, Step: 320, Loss: 4.28493\n",
      "Epoch: 0, Step: 330, Loss: 4.52389\n",
      "Epoch: 0, Step: 340, Loss: 4.33887\n",
      "Epoch: 0, Step: 350, Loss: 4.16382\n",
      "Epoch: 0, Step: 360, Loss: 4.08966\n",
      "Epoch: 0, Step: 370, Loss: 4.09682\n",
      "Epoch: 0, Step: 380, Loss: 4.11466\n",
      "Epoch: 0, Step: 390, Loss: 3.92949\n",
      "Epoch: 0, Step: 400, Loss: 3.85628\n",
      "Epoch: 0, Step: 410, Loss: 3.85977\n",
      "Epoch: 0, Step: 420, Loss: 3.85768\n",
      "Epoch: 0, Step: 430, Loss: 3.76339\n",
      "Epoch: 0, Step: 440, Loss: 3.8174\n",
      "Epoch: 0, Step: 450, Loss: 3.88609\n",
      "Epoch: 1, Step: 100, Loss: 4.17452\n",
      "Epoch: 1, Step: 110, Loss: 3.842\n",
      "Epoch: 1, Step: 120, Loss: 3.78357\n",
      "Epoch: 1, Step: 130, Loss: 3.61689\n",
      "Epoch: 1, Step: 140, Loss: 3.69434\n",
      "Epoch: 1, Step: 150, Loss: 3.67153\n",
      "Epoch: 1, Step: 160, Loss: 3.48419\n",
      "Epoch: 1, Step: 170, Loss: 3.52261\n",
      "Epoch: 1, Step: 180, Loss: 3.38539\n",
      "Epoch: 1, Step: 190, Loss: 3.77958\n",
      "Epoch: 1, Step: 200, Loss: 3.3467\n",
      "Epoch: 1, Step: 210, Loss: 3.21906\n",
      "Epoch: 1, Step: 220, Loss: 3.19584\n",
      "Epoch: 1, Step: 230, Loss: 3.34086\n",
      "Epoch: 1, Step: 240, Loss: 3.08058\n",
      "Epoch: 1, Step: 250, Loss: 3.01281\n",
      "Epoch: 1, Step: 260, Loss: 3.12977\n",
      "Epoch: 1, Step: 270, Loss: 3.16182\n",
      "Epoch: 1, Step: 280, Loss: 2.92658\n",
      "Epoch: 1, Step: 290, Loss: 3.11715\n",
      "Epoch: 1, Step: 300, Loss: 2.90901\n",
      "Epoch: 1, Step: 310, Loss: 3.0081\n",
      "Epoch: 1, Step: 320, Loss: 2.89679\n",
      "Epoch: 1, Step: 330, Loss: 3.01634\n",
      "Epoch: 1, Step: 340, Loss: 3.03814\n",
      "Epoch: 1, Step: 350, Loss: 2.83747\n",
      "Epoch: 1, Step: 360, Loss: 2.62935\n",
      "Epoch: 1, Step: 370, Loss: 2.62308\n",
      "Epoch: 1, Step: 380, Loss: 2.81241\n",
      "Epoch: 1, Step: 390, Loss: 2.66118\n",
      "Epoch: 1, Step: 400, Loss: 2.74496\n",
      "Epoch: 1, Step: 410, Loss: 2.48778\n",
      "Epoch: 1, Step: 420, Loss: 2.86694\n",
      "Epoch: 1, Step: 430, Loss: 2.52635\n",
      "Epoch: 1, Step: 440, Loss: 2.58007\n",
      "Epoch: 1, Step: 450, Loss: 2.53319\n",
      "Epoch: 1, Step: 460, Loss: 2.3845\n",
      "Epoch: 1, Step: 470, Loss: 2.50513\n",
      "Epoch: 1, Step: 480, Loss: 2.67894\n",
      "Epoch: 1, Step: 490, Loss: 3.21922\n",
      "Epoch: 1, Step: 500, Loss: 2.41721\n",
      "Epoch: 1, Step: 510, Loss: 2.45737\n",
      "Epoch: 1, Step: 520, Loss: 2.25627\n",
      "Epoch: 1, Step: 530, Loss: 2.22399\n",
      "Epoch: 1, Step: 540, Loss: 2.94414\n",
      "Epoch: 1, Step: 550, Loss: 2.1724\n",
      "Epoch: 2, Step: 200, Loss: 2.38274\n",
      "Epoch: 2, Step: 210, Loss: 2.32178\n",
      "Epoch: 2, Step: 220, Loss: 2.31441\n",
      "Epoch: 2, Step: 230, Loss: 2.28096\n",
      "Epoch: 2, Step: 240, Loss: 2.22832\n",
      "Epoch: 2, Step: 250, Loss: 2.26089\n",
      "Epoch: 2, Step: 260, Loss: 1.98021\n",
      "Epoch: 2, Step: 270, Loss: 2.28353\n",
      "Epoch: 2, Step: 280, Loss: 2.21818\n",
      "Epoch: 2, Step: 290, Loss: 2.1201\n",
      "Epoch: 2, Step: 300, Loss: 1.99192\n",
      "Epoch: 2, Step: 310, Loss: 2.09404\n",
      "Epoch: 2, Step: 320, Loss: 1.9386\n",
      "Epoch: 2, Step: 330, Loss: 1.99259\n",
      "Epoch: 2, Step: 340, Loss: 2.12723\n",
      "Epoch: 2, Step: 350, Loss: 2.05623\n",
      "Epoch: 2, Step: 360, Loss: 1.94022\n",
      "Epoch: 2, Step: 370, Loss: 2.01106\n",
      "Epoch: 2, Step: 380, Loss: 2.00312\n",
      "Epoch: 2, Step: 390, Loss: 1.73654\n",
      "Epoch: 2, Step: 400, Loss: 1.94387\n",
      "Epoch: 2, Step: 410, Loss: 2.25172\n",
      "Epoch: 2, Step: 420, Loss: 1.96223\n",
      "Epoch: 2, Step: 430, Loss: 2.03564\n",
      "Epoch: 2, Step: 440, Loss: 1.74787\n",
      "Epoch: 2, Step: 450, Loss: 1.69289\n",
      "Epoch: 2, Step: 460, Loss: 1.95433\n",
      "Epoch: 2, Step: 470, Loss: 1.67644\n",
      "Epoch: 2, Step: 480, Loss: 1.60759\n",
      "Epoch: 2, Step: 490, Loss: 1.78117\n",
      "Epoch: 2, Step: 500, Loss: 1.63717\n",
      "Epoch: 2, Step: 510, Loss: 1.61253\n",
      "Epoch: 2, Step: 520, Loss: 1.80857\n",
      "Epoch: 2, Step: 530, Loss: 1.74401\n",
      "Epoch: 2, Step: 540, Loss: 1.53512\n",
      "Epoch: 2, Step: 550, Loss: 1.49467\n",
      "Epoch: 2, Step: 560, Loss: 1.621\n",
      "Epoch: 2, Step: 570, Loss: 1.54064\n",
      "Epoch: 2, Step: 580, Loss: 1.47881\n",
      "Epoch: 2, Step: 590, Loss: 1.3935\n",
      "Epoch: 2, Step: 600, Loss: 1.44915\n",
      "Epoch: 2, Step: 610, Loss: 1.47529\n",
      "Epoch: 2, Step: 620, Loss: 1.46775\n",
      "Epoch: 2, Step: 630, Loss: 1.46882\n",
      "Epoch: 2, Step: 640, Loss: 1.60813\n",
      "Epoch: 2, Step: 650, Loss: 1.87936\n",
      "Epoch: 3, Step: 300, Loss: 1.63109\n",
      "Epoch: 3, Step: 310, Loss: 1.47608\n",
      "Epoch: 3, Step: 320, Loss: 1.51639\n",
      "Epoch: 3, Step: 330, Loss: 1.51333\n",
      "Epoch: 3, Step: 340, Loss: 1.45354\n",
      "Epoch: 3, Step: 350, Loss: 1.39703\n",
      "Epoch: 3, Step: 360, Loss: 1.46089\n",
      "Epoch: 3, Step: 370, Loss: 1.55488\n",
      "Epoch: 3, Step: 380, Loss: 1.48821\n",
      "Epoch: 3, Step: 390, Loss: 1.39283\n",
      "Epoch: 3, Step: 400, Loss: 1.20072\n",
      "Epoch: 3, Step: 410, Loss: 1.24036\n",
      "Epoch: 3, Step: 420, Loss: 1.34884\n",
      "Epoch: 3, Step: 430, Loss: 1.17124\n",
      "Epoch: 3, Step: 440, Loss: 1.13021\n",
      "Epoch: 3, Step: 450, Loss: 1.27201\n",
      "Epoch: 3, Step: 460, Loss: 1.31644\n",
      "Epoch: 3, Step: 470, Loss: 1.18193\n",
      "Epoch: 3, Step: 480, Loss: 1.25235\n",
      "Epoch: 3, Step: 490, Loss: 1.15281\n",
      "Epoch: 3, Step: 500, Loss: 1.28843\n",
      "Epoch: 3, Step: 510, Loss: 1.14246\n",
      "Epoch: 3, Step: 520, Loss: 1.29111\n",
      "Epoch: 3, Step: 530, Loss: 1.40482\n",
      "Epoch: 3, Step: 540, Loss: 1.123\n",
      "Epoch: 3, Step: 550, Loss: 0.994648\n",
      "Epoch: 3, Step: 560, Loss: 1.02022\n",
      "Epoch: 3, Step: 570, Loss: 1.20222\n",
      "Epoch: 3, Step: 580, Loss: 1.06337\n",
      "Epoch: 3, Step: 590, Loss: 1.17095\n",
      "Epoch: 3, Step: 600, Loss: 1.07282\n",
      "Epoch: 3, Step: 610, Loss: 1.2216\n",
      "Epoch: 3, Step: 620, Loss: 1.11808\n",
      "Epoch: 3, Step: 630, Loss: 1.03912\n",
      "Epoch: 3, Step: 640, Loss: 1.02574\n",
      "Epoch: 3, Step: 650, Loss: 0.935282\n",
      "Epoch: 3, Step: 660, Loss: 1.09151\n",
      "Epoch: 3, Step: 670, Loss: 1.26882\n",
      "Epoch: 3, Step: 680, Loss: 1.84929\n",
      "Epoch: 3, Step: 690, Loss: 1.06194\n",
      "Epoch: 3, Step: 700, Loss: 1.0226\n",
      "Epoch: 3, Step: 710, Loss: 0.933316\n",
      "Epoch: 3, Step: 720, Loss: 1.63348\n",
      "Epoch: 3, Step: 730, Loss: 0.915559\n",
      "Epoch: 3, Step: 740, Loss: 0.835998\n",
      "Epoch: 3, Step: 750, Loss: 1.15147\n",
      "Epoch: 4, Step: 400, Loss: 1.09354\n",
      "Epoch: 4, Step: 410, Loss: 1.20067\n",
      "Epoch: 4, Step: 420, Loss: 0.796892\n",
      "Epoch: 4, Step: 430, Loss: 1.09105\n",
      "Epoch: 4, Step: 440, Loss: 0.966128\n",
      "Epoch: 4, Step: 450, Loss: 0.904098\n",
      "Epoch: 4, Step: 460, Loss: 1.06097\n",
      "Epoch: 4, Step: 470, Loss: 0.973047\n",
      "Epoch: 4, Step: 480, Loss: 0.963885\n",
      "Epoch: 4, Step: 490, Loss: 0.854366\n",
      "Epoch: 4, Step: 500, Loss: 0.998907\n",
      "Epoch: 4, Step: 510, Loss: 0.789866\n",
      "Epoch: 4, Step: 520, Loss: 0.898474\n",
      "Epoch: 4, Step: 530, Loss: 1.06219\n",
      "Epoch: 4, Step: 540, Loss: 1.00029\n",
      "Epoch: 4, Step: 550, Loss: 0.896652\n",
      "Epoch: 4, Step: 560, Loss: 0.936036\n",
      "Epoch: 4, Step: 570, Loss: 0.94553\n",
      "Epoch: 4, Step: 580, Loss: 0.748231\n",
      "Epoch: 4, Step: 590, Loss: 0.93895\n",
      "Epoch: 4, Step: 600, Loss: 1.26638\n",
      "Epoch: 4, Step: 610, Loss: 0.953533\n",
      "Epoch: 4, Step: 620, Loss: 1.04506\n",
      "Epoch: 4, Step: 630, Loss: 0.785572\n",
      "Epoch: 4, Step: 640, Loss: 0.772014\n",
      "Epoch: 4, Step: 650, Loss: 1.03494\n",
      "Epoch: 4, Step: 660, Loss: 0.714011\n",
      "Epoch: 4, Step: 670, Loss: 0.712128\n",
      "Epoch: 4, Step: 680, Loss: 0.852151\n",
      "Epoch: 4, Step: 690, Loss: 0.776811\n",
      "Epoch: 4, Step: 700, Loss: 0.704512\n",
      "Epoch: 4, Step: 710, Loss: 1.0288\n",
      "Epoch: 4, Step: 720, Loss: 0.795139\n",
      "Epoch: 4, Step: 730, Loss: 0.720258\n",
      "Epoch: 4, Step: 740, Loss: 0.723345\n",
      "Epoch: 4, Step: 750, Loss: 0.735562\n",
      "Epoch: 4, Step: 760, Loss: 0.720595\n",
      "Epoch: 4, Step: 770, Loss: 0.623834\n",
      "Epoch: 4, Step: 780, Loss: 0.596439\n",
      "Epoch: 4, Step: 790, Loss: 0.654501\n",
      "Epoch: 4, Step: 800, Loss: 0.70294\n",
      "Epoch: 4, Step: 810, Loss: 0.712097\n",
      "Epoch: 4, Step: 820, Loss: 0.911198\n",
      "Epoch: 4, Step: 830, Loss: 0.721349\n",
      "Epoch: 4, Step: 840, Loss: 1.07021\n",
      "Epoch: 4, Step: 850, Loss: 0.997954\n",
      "Epoch: 5, Step: 500, Loss: 0.632983\n",
      "Epoch: 5, Step: 510, Loss: 0.826849\n",
      "Epoch: 5, Step: 520, Loss: 0.754343\n",
      "Epoch: 5, Step: 530, Loss: 0.827278\n",
      "Epoch: 5, Step: 540, Loss: 0.61894\n",
      "Epoch: 5, Step: 550, Loss: 0.816328\n",
      "Epoch: 5, Step: 560, Loss: 0.834295\n",
      "Epoch: 5, Step: 570, Loss: 0.821903\n",
      "Epoch: 5, Step: 580, Loss: 0.725577\n",
      "Epoch: 5, Step: 590, Loss: 0.588818\n",
      "Epoch: 5, Step: 600, Loss: 0.604851\n",
      "Epoch: 5, Step: 610, Loss: 0.647991\n",
      "Epoch: 5, Step: 620, Loss: 0.558076\n",
      "Epoch: 5, Step: 630, Loss: 0.54194\n",
      "Epoch: 5, Step: 640, Loss: 0.626882\n",
      "Epoch: 5, Step: 650, Loss: 0.690746\n",
      "Epoch: 5, Step: 660, Loss: 0.62427\n",
      "Epoch: 5, Step: 670, Loss: 0.647837\n",
      "Epoch: 5, Step: 680, Loss: 0.521984\n",
      "Epoch: 5, Step: 690, Loss: 0.706185\n",
      "Epoch: 5, Step: 700, Loss: 0.705158\n",
      "Epoch: 5, Step: 710, Loss: 0.601579\n",
      "Epoch: 5, Step: 720, Loss: 0.821352\n",
      "Epoch: 5, Step: 730, Loss: 0.564606\n",
      "Epoch: 5, Step: 740, Loss: 0.473103\n",
      "Epoch: 5, Step: 750, Loss: 0.567651\n",
      "Epoch: 5, Step: 760, Loss: 0.566128\n",
      "Epoch: 5, Step: 770, Loss: 0.573434\n",
      "Epoch: 5, Step: 780, Loss: 0.603296\n",
      "Epoch: 5, Step: 790, Loss: 0.697568\n",
      "Epoch: 5, Step: 800, Loss: 0.567171\n",
      "Epoch: 5, Step: 810, Loss: 0.621206\n",
      "Epoch: 5, Step: 820, Loss: 0.564267\n",
      "Epoch: 5, Step: 830, Loss: 0.51757\n",
      "Epoch: 5, Step: 840, Loss: 0.475019\n",
      "Epoch: 5, Step: 850, Loss: 0.7468\n",
      "Epoch: 5, Step: 860, Loss: 0.742653\n",
      "Epoch: 5, Step: 870, Loss: 1.27378\n",
      "Epoch: 5, Step: 880, Loss: 0.686303\n",
      "Epoch: 5, Step: 890, Loss: 0.471479\n",
      "Epoch: 5, Step: 900, Loss: 0.483368\n",
      "Epoch: 5, Step: 910, Loss: 1.18309\n",
      "Epoch: 5, Step: 920, Loss: 0.467688\n",
      "Epoch: 5, Step: 930, Loss: 0.391375\n",
      "Epoch: 5, Step: 940, Loss: 0.902712\n",
      "Epoch: 5, Step: 950, Loss: 0.48526\n",
      "Epoch: 6, Step: 600, Loss: 0.778939\n",
      "Epoch: 6, Step: 610, Loss: 0.366429\n",
      "Epoch: 6, Step: 620, Loss: 0.767243\n",
      "Epoch: 6, Step: 630, Loss: 0.469106\n",
      "Epoch: 6, Step: 640, Loss: 0.490501\n",
      "Epoch: 6, Step: 650, Loss: 0.69349\n",
      "Epoch: 6, Step: 660, Loss: 0.634857\n",
      "Epoch: 6, Step: 670, Loss: 0.512378\n",
      "Epoch: 6, Step: 680, Loss: 0.443885\n",
      "Epoch: 6, Step: 690, Loss: 0.645368\n",
      "Epoch: 6, Step: 700, Loss: 0.398931\n",
      "Epoch: 6, Step: 710, Loss: 0.489432\n",
      "Epoch: 6, Step: 720, Loss: 0.704701\n",
      "Epoch: 6, Step: 730, Loss: 0.618929\n",
      "Epoch: 6, Step: 740, Loss: 0.566327\n",
      "Epoch: 6, Step: 750, Loss: 0.586622\n",
      "Epoch: 6, Step: 760, Loss: 0.560612\n",
      "Epoch: 6, Step: 770, Loss: 0.397863\n",
      "Epoch: 6, Step: 780, Loss: 0.621324\n",
      "Epoch: 6, Step: 790, Loss: 1.01709\n",
      "Epoch: 6, Step: 800, Loss: 0.528154\n",
      "Epoch: 6, Step: 810, Loss: 0.795861\n",
      "Epoch: 6, Step: 820, Loss: 0.383518\n",
      "Epoch: 6, Step: 830, Loss: 0.450517\n",
      "Epoch: 6, Step: 840, Loss: 0.673453\n",
      "Epoch: 6, Step: 850, Loss: 0.400679\n",
      "Epoch: 6, Step: 860, Loss: 0.414676\n",
      "Epoch: 6, Step: 870, Loss: 0.618096\n",
      "Epoch: 6, Step: 880, Loss: 0.375806\n",
      "Epoch: 6, Step: 890, Loss: 0.719662\n",
      "Epoch: 6, Step: 900, Loss: 0.436452\n",
      "Epoch: 6, Step: 910, Loss: 0.521257\n",
      "Epoch: 6, Step: 920, Loss: 0.348879\n",
      "Epoch: 6, Step: 930, Loss: 0.466252\n",
      "Epoch: 6, Step: 940, Loss: 0.416458\n",
      "Epoch: 6, Step: 950, Loss: 0.46658\n",
      "Epoch: 6, Step: 960, Loss: 0.317885\n",
      "Epoch: 6, Step: 970, Loss: 0.376439\n",
      "Epoch: 6, Step: 980, Loss: 0.33385\n",
      "Epoch: 6, Step: 990, Loss: 0.443904\n",
      "Epoch: 6, Step: 1000, Loss: 0.514551\n",
      "Epoch: 6, Step: 1010, Loss: 0.551399\n",
      "Epoch: 6, Step: 1020, Loss: 0.584028\n",
      "Epoch: 6, Step: 1030, Loss: 0.768841\n",
      "Epoch: 6, Step: 1040, Loss: 0.717809\n",
      "Epoch: 6, Step: 1050, Loss: 0.337814\n",
      "Epoch: 7, Step: 700, Loss: 0.676313\n",
      "Epoch: 7, Step: 710, Loss: 0.425174\n",
      "Epoch: 7, Step: 720, Loss: 0.508182\n",
      "Epoch: 7, Step: 730, Loss: 0.411853\n",
      "Epoch: 7, Step: 740, Loss: 0.543509\n",
      "Epoch: 7, Step: 750, Loss: 0.591391\n",
      "Epoch: 7, Step: 760, Loss: 0.602088\n",
      "Epoch: 7, Step: 770, Loss: 0.501236\n",
      "Epoch: 7, Step: 780, Loss: 0.342006\n",
      "Epoch: 7, Step: 790, Loss: 0.431029\n",
      "Epoch: 7, Step: 800, Loss: 0.382378\n",
      "Epoch: 7, Step: 810, Loss: 0.301452\n",
      "Epoch: 7, Step: 820, Loss: 0.357433\n",
      "Epoch: 7, Step: 830, Loss: 0.434796\n",
      "Epoch: 7, Step: 840, Loss: 0.425964\n",
      "Epoch: 7, Step: 850, Loss: 0.385661\n",
      "Epoch: 7, Step: 860, Loss: 0.458608\n",
      "Epoch: 7, Step: 870, Loss: 0.439468\n",
      "Epoch: 7, Step: 880, Loss: 0.367241\n",
      "Epoch: 7, Step: 890, Loss: 0.490798\n",
      "Epoch: 7, Step: 900, Loss: 0.496278\n",
      "Epoch: 7, Step: 910, Loss: 0.498205\n",
      "Epoch: 7, Step: 920, Loss: 0.368838\n",
      "Epoch: 7, Step: 930, Loss: 0.268098\n",
      "Epoch: 7, Step: 940, Loss: 0.484822\n",
      "Epoch: 7, Step: 950, Loss: 0.264566\n",
      "Epoch: 7, Step: 960, Loss: 0.379216\n",
      "Epoch: 7, Step: 970, Loss: 0.418321\n",
      "Epoch: 7, Step: 980, Loss: 0.509207\n",
      "Epoch: 7, Step: 990, Loss: 0.374973\n",
      "Epoch: 7, Step: 1000, Loss: 0.438354\n",
      "Epoch: 7, Step: 1010, Loss: 0.425671\n",
      "Epoch: 7, Step: 1020, Loss: 0.30905\n",
      "Epoch: 7, Step: 1030, Loss: 0.284707\n",
      "Epoch: 7, Step: 1040, Loss: 0.579064\n",
      "Epoch: 7, Step: 1050, Loss: 0.575412\n",
      "Epoch: 7, Step: 1060, Loss: 1.20503\n",
      "Epoch: 7, Step: 1070, Loss: 0.403023\n",
      "Epoch: 7, Step: 1080, Loss: 0.319059\n",
      "Epoch: 7, Step: 1090, Loss: 0.285681\n",
      "Epoch: 7, Step: 1100, Loss: 1.02347\n",
      "Epoch: 7, Step: 1110, Loss: 0.295717\n",
      "Epoch: 7, Step: 1120, Loss: 0.385356\n",
      "Epoch: 7, Step: 1130, Loss: 0.585203\n",
      "Epoch: 7, Step: 1140, Loss: 0.48036\n",
      "Epoch: 7, Step: 1150, Loss: 0.456759\n",
      "Epoch: 8, Step: 800, Loss: 0.293767\n",
      "Epoch: 8, Step: 810, Loss: 0.562737\n",
      "Epoch: 8, Step: 820, Loss: 0.279212\n",
      "Epoch: 8, Step: 830, Loss: 0.418061\n",
      "Epoch: 8, Step: 840, Loss: 0.477902\n",
      "Epoch: 8, Step: 850, Loss: 0.526908\n",
      "Epoch: 8, Step: 860, Loss: 0.310552\n",
      "Epoch: 8, Step: 870, Loss: 0.433866\n",
      "Epoch: 8, Step: 880, Loss: 0.365803\n",
      "Epoch: 8, Step: 890, Loss: 0.276345\n",
      "Epoch: 8, Step: 900, Loss: 0.33352\n",
      "Epoch: 8, Step: 910, Loss: 0.546134\n",
      "Epoch: 8, Step: 920, Loss: 0.495315\n",
      "Epoch: 8, Step: 930, Loss: 0.600614\n",
      "Epoch: 8, Step: 940, Loss: 0.461827\n",
      "Epoch: 8, Step: 950, Loss: 0.22673\n",
      "Epoch: 8, Step: 960, Loss: 0.264559\n",
      "Epoch: 8, Step: 970, Loss: 0.553273\n",
      "Epoch: 8, Step: 980, Loss: 0.893316\n",
      "Epoch: 8, Step: 990, Loss: 0.466768\n",
      "Epoch: 8, Step: 1000, Loss: 0.520645\n",
      "Epoch: 8, Step: 1010, Loss: 0.278365\n",
      "Epoch: 8, Step: 1020, Loss: 0.335633\n",
      "Epoch: 8, Step: 1030, Loss: 0.551742\n",
      "Epoch: 8, Step: 1040, Loss: 0.309263\n",
      "Epoch: 8, Step: 1050, Loss: 0.225876\n",
      "Epoch: 8, Step: 1060, Loss: 0.500567\n",
      "Epoch: 8, Step: 1070, Loss: 0.282557\n",
      "Epoch: 8, Step: 1080, Loss: 0.56624\n",
      "Epoch: 8, Step: 1090, Loss: 0.317472\n",
      "Epoch: 8, Step: 1100, Loss: 0.402563\n",
      "Epoch: 8, Step: 1110, Loss: 0.253063\n",
      "Epoch: 8, Step: 1120, Loss: 0.352628\n",
      "Epoch: 8, Step: 1130, Loss: 0.283436\n",
      "Epoch: 8, Step: 1140, Loss: 0.353199\n",
      "Epoch: 8, Step: 1150, Loss: 0.230238\n",
      "Epoch: 8, Step: 1160, Loss: 0.24859\n",
      "Epoch: 8, Step: 1170, Loss: 0.347971\n",
      "Epoch: 8, Step: 1180, Loss: 0.211725\n",
      "Epoch: 8, Step: 1190, Loss: 0.408846\n",
      "Epoch: 8, Step: 1200, Loss: 0.445851\n",
      "Epoch: 8, Step: 1210, Loss: 0.695756\n",
      "Epoch: 8, Step: 1220, Loss: 0.468605\n",
      "Epoch: 8, Step: 1230, Loss: 0.598278\n",
      "Epoch: 8, Step: 1240, Loss: 0.311873\n",
      "Epoch: 8, Step: 1250, Loss: 0.504034\n",
      "Epoch: 9, Step: 900, Loss: 0.470956\n",
      "Epoch: 9, Step: 910, Loss: 0.268123\n",
      "Epoch: 9, Step: 920, Loss: 0.390499\n",
      "Epoch: 9, Step: 930, Loss: 0.374264\n",
      "Epoch: 9, Step: 940, Loss: 0.753464\n",
      "Epoch: 9, Step: 950, Loss: 0.210225\n",
      "Epoch: 9, Step: 960, Loss: 0.403055\n",
      "Epoch: 9, Step: 970, Loss: 0.24208\n",
      "Epoch: 9, Step: 980, Loss: 0.346348\n",
      "Epoch: 9, Step: 990, Loss: 0.297857\n",
      "Epoch: 9, Step: 1000, Loss: 0.197782\n",
      "Epoch: 9, Step: 1010, Loss: 0.358318\n",
      "Epoch: 9, Step: 1020, Loss: 0.399334\n",
      "Epoch: 9, Step: 1030, Loss: 0.207248\n",
      "Epoch: 9, Step: 1040, Loss: 0.287382\n",
      "Epoch: 9, Step: 1050, Loss: 0.376328\n",
      "Epoch: 9, Step: 1060, Loss: 0.331154\n",
      "Epoch: 9, Step: 1070, Loss: 0.354355\n",
      "Epoch: 9, Step: 1080, Loss: 0.461711\n",
      "Epoch: 9, Step: 1090, Loss: 0.34069\n",
      "Epoch: 9, Step: 1100, Loss: 0.448956\n",
      "Epoch: 9, Step: 1110, Loss: 0.180418\n",
      "Epoch: 9, Step: 1120, Loss: 0.194955\n",
      "Epoch: 9, Step: 1130, Loss: 0.398001\n",
      "Epoch: 9, Step: 1140, Loss: 0.196684\n",
      "Epoch: 9, Step: 1150, Loss: 0.304498\n",
      "Epoch: 9, Step: 1160, Loss: 0.316938\n",
      "Epoch: 9, Step: 1170, Loss: 0.426975\n",
      "Epoch: 9, Step: 1180, Loss: 0.339506\n",
      "Epoch: 9, Step: 1190, Loss: 0.339431\n",
      "Epoch: 9, Step: 1200, Loss: 0.31746\n",
      "Epoch: 9, Step: 1210, Loss: 0.236599\n",
      "Epoch: 9, Step: 1220, Loss: 0.357256\n",
      "Epoch: 9, Step: 1230, Loss: 0.36863\n",
      "Epoch: 9, Step: 1240, Loss: 0.528384\n",
      "Epoch: 9, Step: 1250, Loss: 1.08527\n",
      "Epoch: 9, Step: 1260, Loss: 0.407766\n",
      "Epoch: 9, Step: 1270, Loss: 0.217786\n",
      "Epoch: 9, Step: 1280, Loss: 0.167304\n",
      "Epoch: 9, Step: 1290, Loss: 0.978688\n",
      "Epoch: 9, Step: 1300, Loss: 0.195299\n",
      "Epoch: 9, Step: 1310, Loss: 0.345561\n",
      "Epoch: 9, Step: 1320, Loss: 0.485439\n",
      "Epoch: 9, Step: 1330, Loss: 0.40661\n",
      "Epoch: 9, Step: 1340, Loss: 0.395582\n",
      "Epoch: 9, Step: 1350, Loss: 0.247071\n",
      "Epoch: 10, Step: 1000, Loss: 0.489561\n",
      "Epoch: 10, Step: 1010, Loss: 0.208446\n",
      "Epoch: 10, Step: 1020, Loss: 0.33847\n",
      "Epoch: 10, Step: 1030, Loss: 0.52554\n",
      "Epoch: 10, Step: 1040, Loss: 0.399177\n",
      "Epoch: 10, Step: 1050, Loss: 0.250966\n",
      "Epoch: 10, Step: 1060, Loss: 0.342079\n",
      "Epoch: 10, Step: 1070, Loss: 0.277918\n",
      "Epoch: 10, Step: 1080, Loss: 0.215015\n",
      "Epoch: 10, Step: 1090, Loss: 0.326103\n",
      "Epoch: 10, Step: 1100, Loss: 0.600115\n",
      "Epoch: 10, Step: 1110, Loss: 0.242626\n",
      "Epoch: 10, Step: 1120, Loss: 0.539404\n",
      "Epoch: 10, Step: 1130, Loss: 0.408799\n",
      "Epoch: 10, Step: 1140, Loss: 0.154306\n",
      "Epoch: 10, Step: 1150, Loss: 0.322859\n",
      "Epoch: 10, Step: 1160, Loss: 0.370417\n",
      "Epoch: 10, Step: 1170, Loss: 0.926478\n",
      "Epoch: 10, Step: 1180, Loss: 0.326137\n",
      "Epoch: 10, Step: 1190, Loss: 0.449551\n",
      "Epoch: 10, Step: 1200, Loss: 0.272097\n",
      "Epoch: 10, Step: 1210, Loss: 0.420518\n",
      "Epoch: 10, Step: 1220, Loss: 0.314027\n",
      "Epoch: 10, Step: 1230, Loss: 0.246289\n",
      "Epoch: 10, Step: 1240, Loss: 0.334065\n",
      "Epoch: 10, Step: 1250, Loss: 0.285816\n",
      "Epoch: 10, Step: 1260, Loss: 0.21307\n",
      "Epoch: 10, Step: 1270, Loss: 0.509938\n",
      "Epoch: 10, Step: 1280, Loss: 0.3772\n",
      "Epoch: 10, Step: 1290, Loss: 0.253883\n",
      "Epoch: 10, Step: 1300, Loss: 0.212526\n",
      "Epoch: 10, Step: 1310, Loss: 0.266616\n",
      "Epoch: 10, Step: 1320, Loss: 0.325523\n",
      "Epoch: 10, Step: 1330, Loss: 0.228507\n",
      "Epoch: 10, Step: 1340, Loss: 0.165618\n",
      "Epoch: 10, Step: 1350, Loss: 0.2106\n",
      "Epoch: 10, Step: 1360, Loss: 0.285921\n",
      "Epoch: 10, Step: 1370, Loss: 0.217575\n",
      "Epoch: 10, Step: 1380, Loss: 0.310279\n",
      "Epoch: 10, Step: 1390, Loss: 0.424552\n",
      "Epoch: 10, Step: 1400, Loss: 0.732837\n",
      "Epoch: 10, Step: 1410, Loss: 0.357575\n",
      "Epoch: 10, Step: 1420, Loss: 0.500513\n",
      "Epoch: 10, Step: 1430, Loss: 0.284837\n",
      "Epoch: 10, Step: 1440, Loss: 0.418115\n",
      "Epoch: 10, Step: 1450, Loss: 0.414767\n",
      "Epoch: 11, Step: 1100, Loss: 0.261294\n",
      "Epoch: 11, Step: 1110, Loss: 0.37806\n",
      "Epoch: 11, Step: 1120, Loss: 0.271989\n",
      "Epoch: 11, Step: 1130, Loss: 0.703807\n",
      "Epoch: 11, Step: 1140, Loss: 0.275499\n",
      "Epoch: 11, Step: 1150, Loss: 0.226711\n",
      "Epoch: 11, Step: 1160, Loss: 0.214435\n",
      "Epoch: 11, Step: 1170, Loss: 0.393624\n",
      "Epoch: 11, Step: 1180, Loss: 0.175563\n",
      "Epoch: 11, Step: 1190, Loss: 0.13464\n",
      "Epoch: 11, Step: 1200, Loss: 0.30287\n",
      "Epoch: 11, Step: 1210, Loss: 0.352328\n",
      "Epoch: 11, Step: 1220, Loss: 0.164502\n",
      "Epoch: 11, Step: 1230, Loss: 0.366581\n",
      "Epoch: 11, Step: 1240, Loss: 0.226683\n",
      "Epoch: 11, Step: 1250, Loss: 0.271115\n",
      "Epoch: 11, Step: 1260, Loss: 0.321489\n",
      "Epoch: 11, Step: 1270, Loss: 0.408481\n",
      "Epoch: 11, Step: 1280, Loss: 0.39958\n",
      "Epoch: 11, Step: 1290, Loss: 0.360058\n",
      "Epoch: 11, Step: 1300, Loss: 0.104896\n",
      "Epoch: 11, Step: 1310, Loss: 0.14945\n",
      "Epoch: 11, Step: 1320, Loss: 0.359542\n",
      "Epoch: 11, Step: 1330, Loss: 0.222897\n",
      "Epoch: 11, Step: 1340, Loss: 0.359314\n",
      "Epoch: 11, Step: 1350, Loss: 0.119174\n",
      "Epoch: 11, Step: 1360, Loss: 0.533735\n",
      "Epoch: 11, Step: 1370, Loss: 0.218215\n",
      "Epoch: 11, Step: 1380, Loss: 0.221783\n",
      "Epoch: 11, Step: 1390, Loss: 0.348298\n",
      "Epoch: 11, Step: 1400, Loss: 0.141107\n",
      "Epoch: 11, Step: 1410, Loss: 0.320932\n",
      "Epoch: 11, Step: 1420, Loss: 0.401859\n",
      "Epoch: 11, Step: 1430, Loss: 1.18439\n",
      "Epoch: 11, Step: 1440, Loss: 0.286109\n",
      "Epoch: 11, Step: 1450, Loss: 0.355576\n",
      "Epoch: 11, Step: 1460, Loss: 0.182964\n",
      "Epoch: 11, Step: 1470, Loss: 0.132587\n",
      "Epoch: 11, Step: 1480, Loss: 0.954924\n",
      "Epoch: 11, Step: 1490, Loss: 0.160877\n",
      "Epoch: 11, Step: 1500, Loss: 0.397419\n",
      "Epoch: 11, Step: 1510, Loss: 0.359162\n",
      "Epoch: 11, Step: 1520, Loss: 0.367053\n",
      "Epoch: 11, Step: 1530, Loss: 0.350552\n",
      "Epoch: 11, Step: 1540, Loss: 0.338495\n",
      "Epoch: 11, Step: 1550, Loss: 0.366724\n",
      "Epoch: 12, Step: 1200, Loss: 0.128021\n",
      "Epoch: 12, Step: 1210, Loss: 0.451016\n",
      "Epoch: 12, Step: 1220, Loss: 0.397541\n",
      "Epoch: 12, Step: 1230, Loss: 0.325232\n",
      "Epoch: 12, Step: 1240, Loss: 0.220016\n",
      "Epoch: 12, Step: 1250, Loss: 0.342897\n",
      "Epoch: 12, Step: 1260, Loss: 0.205132\n",
      "Epoch: 12, Step: 1270, Loss: 0.284361\n",
      "Epoch: 12, Step: 1280, Loss: 0.436477\n",
      "Epoch: 12, Step: 1290, Loss: 0.373698\n",
      "Epoch: 12, Step: 1300, Loss: 0.289496\n",
      "Epoch: 12, Step: 1310, Loss: 0.395018\n",
      "Epoch: 12, Step: 1320, Loss: 0.386755\n",
      "Epoch: 12, Step: 1330, Loss: 0.140032\n",
      "Epoch: 12, Step: 1340, Loss: 0.377451\n",
      "Epoch: 12, Step: 1350, Loss: 0.693761\n",
      "Epoch: 12, Step: 1360, Loss: 0.419624\n",
      "Epoch: 12, Step: 1370, Loss: 0.503663\n",
      "Epoch: 12, Step: 1380, Loss: 0.25775\n",
      "Epoch: 12, Step: 1390, Loss: 0.200295\n",
      "Epoch: 12, Step: 1400, Loss: 0.488058\n",
      "Epoch: 12, Step: 1410, Loss: 0.214443\n",
      "Epoch: 12, Step: 1420, Loss: 0.173382\n",
      "Epoch: 12, Step: 1430, Loss: 0.354151\n",
      "Epoch: 12, Step: 1440, Loss: 0.23383\n",
      "Epoch: 12, Step: 1450, Loss: 0.221905\n",
      "Epoch: 12, Step: 1460, Loss: 0.439012\n",
      "Epoch: 12, Step: 1470, Loss: 0.389464\n",
      "Epoch: 12, Step: 1480, Loss: 0.186483\n",
      "Epoch: 12, Step: 1490, Loss: 0.17235\n",
      "Epoch: 12, Step: 1500, Loss: 0.309154\n",
      "Epoch: 12, Step: 1510, Loss: 0.243828\n",
      "Epoch: 12, Step: 1520, Loss: 0.196804\n",
      "Epoch: 12, Step: 1530, Loss: 0.126306\n",
      "Epoch: 12, Step: 1540, Loss: 0.200127\n",
      "Epoch: 12, Step: 1550, Loss: 0.230224\n",
      "Epoch: 12, Step: 1560, Loss: 0.250744\n",
      "Epoch: 12, Step: 1570, Loss: 0.260667\n",
      "Epoch: 12, Step: 1580, Loss: 0.411544\n",
      "Epoch: 12, Step: 1590, Loss: 0.699433\n",
      "Epoch: 12, Step: 1600, Loss: 0.441689\n",
      "Epoch: 12, Step: 1610, Loss: 0.318406\n",
      "Epoch: 12, Step: 1620, Loss: 0.300202\n",
      "Epoch: 12, Step: 1630, Loss: 0.434923\n",
      "Epoch: 12, Step: 1640, Loss: 0.326916\n",
      "Epoch: 12, Step: 1650, Loss: 0.275829\n",
      "Epoch: 13, Step: 1300, Loss: 0.32409\n",
      "Epoch: 13, Step: 1310, Loss: 0.501743\n",
      "Epoch: 13, Step: 1320, Loss: 0.414569\n",
      "Epoch: 13, Step: 1330, Loss: 0.330896\n",
      "Epoch: 13, Step: 1340, Loss: 0.147601\n",
      "Epoch: 13, Step: 1350, Loss: 0.193588\n",
      "Epoch: 13, Step: 1360, Loss: 0.321388\n",
      "Epoch: 13, Step: 1370, Loss: 0.151747\n",
      "Epoch: 13, Step: 1380, Loss: 0.122242\n",
      "Epoch: 13, Step: 1390, Loss: 0.276018\n",
      "Epoch: 13, Step: 1400, Loss: 0.329314\n",
      "Epoch: 13, Step: 1410, Loss: 0.204979\n",
      "Epoch: 13, Step: 1420, Loss: 0.292971\n",
      "Epoch: 13, Step: 1430, Loss: 0.197188\n",
      "Epoch: 13, Step: 1440, Loss: 0.331464\n",
      "Epoch: 13, Step: 1450, Loss: 0.222682\n",
      "Epoch: 13, Step: 1460, Loss: 0.36615\n",
      "Epoch: 13, Step: 1470, Loss: 0.493441\n",
      "Epoch: 13, Step: 1480, Loss: 0.221363\n",
      "Epoch: 13, Step: 1490, Loss: 0.0946755\n",
      "Epoch: 13, Step: 1500, Loss: 0.145675\n",
      "Epoch: 13, Step: 1510, Loss: 0.322044\n",
      "Epoch: 13, Step: 1520, Loss: 0.206635\n",
      "Epoch: 13, Step: 1530, Loss: 0.317296\n",
      "Epoch: 13, Step: 1540, Loss: 0.222518\n",
      "Epoch: 13, Step: 1550, Loss: 0.391928\n",
      "Epoch: 13, Step: 1560, Loss: 0.296745\n",
      "Epoch: 13, Step: 1570, Loss: 0.191204\n",
      "Epoch: 13, Step: 1580, Loss: 0.243618\n",
      "Epoch: 13, Step: 1590, Loss: 0.130542\n",
      "Epoch: 13, Step: 1600, Loss: 0.307035\n",
      "Epoch: 13, Step: 1610, Loss: 0.475762\n",
      "Epoch: 13, Step: 1620, Loss: 1.09374\n",
      "Epoch: 13, Step: 1630, Loss: 0.232299\n",
      "Epoch: 13, Step: 1640, Loss: 0.321367\n",
      "Epoch: 13, Step: 1650, Loss: 0.170462\n",
      "Epoch: 13, Step: 1660, Loss: 0.88024\n",
      "Epoch: 13, Step: 1670, Loss: 0.17944\n",
      "Epoch: 13, Step: 1680, Loss: 0.138698\n",
      "Epoch: 13, Step: 1690, Loss: 0.42529\n",
      "Epoch: 13, Step: 1700, Loss: 0.315703\n",
      "Epoch: 13, Step: 1710, Loss: 0.540918\n",
      "Epoch: 13, Step: 1720, Loss: 0.120472\n",
      "Epoch: 13, Step: 1730, Loss: 0.394169\n",
      "Epoch: 13, Step: 1740, Loss: 0.2802\n",
      "Epoch: 13, Step: 1750, Loss: 0.127484\n",
      "Epoch: 14, Step: 1400, Loss: 0.484633\n",
      "Epoch: 14, Step: 1410, Loss: 0.310201\n",
      "Epoch: 14, Step: 1420, Loss: 0.295734\n",
      "Epoch: 14, Step: 1430, Loss: 0.20111\n",
      "Epoch: 14, Step: 1440, Loss: 0.371906\n",
      "Epoch: 14, Step: 1450, Loss: 0.13363\n",
      "Epoch: 14, Step: 1460, Loss: 0.279962\n",
      "Epoch: 14, Step: 1470, Loss: 0.445035\n",
      "Epoch: 14, Step: 1480, Loss: 0.381811\n",
      "Epoch: 14, Step: 1490, Loss: 0.282365\n",
      "Epoch: 14, Step: 1500, Loss: 0.324102\n",
      "Epoch: 14, Step: 1510, Loss: 0.363725\n",
      "Epoch: 14, Step: 1520, Loss: 0.147057\n",
      "Epoch: 14, Step: 1530, Loss: 0.356132\n",
      "Epoch: 14, Step: 1540, Loss: 0.695266\n",
      "Epoch: 14, Step: 1550, Loss: 0.375773\n",
      "Epoch: 14, Step: 1560, Loss: 0.475225\n",
      "Epoch: 14, Step: 1570, Loss: 0.230273\n",
      "Epoch: 14, Step: 1580, Loss: 0.218463\n",
      "Epoch: 14, Step: 1590, Loss: 0.46811\n",
      "Epoch: 14, Step: 1600, Loss: 0.181135\n",
      "Epoch: 14, Step: 1610, Loss: 0.148815\n",
      "Epoch: 14, Step: 1620, Loss: 0.343685\n",
      "Epoch: 14, Step: 1630, Loss: 0.24756\n",
      "Epoch: 14, Step: 1640, Loss: 0.180199\n",
      "Epoch: 14, Step: 1650, Loss: 0.508733\n",
      "Epoch: 14, Step: 1660, Loss: 0.279816\n",
      "Epoch: 14, Step: 1670, Loss: 0.2185\n",
      "Epoch: 14, Step: 1680, Loss: 0.208752\n",
      "Epoch: 14, Step: 1690, Loss: 0.215189\n",
      "Epoch: 14, Step: 1700, Loss: 0.253823\n",
      "Epoch: 14, Step: 1710, Loss: 0.151334\n",
      "Epoch: 14, Step: 1720, Loss: 0.114582\n",
      "Epoch: 14, Step: 1730, Loss: 0.175887\n",
      "Epoch: 14, Step: 1740, Loss: 0.222271\n",
      "Epoch: 14, Step: 1750, Loss: 0.253574\n",
      "Epoch: 14, Step: 1760, Loss: 0.313625\n",
      "Epoch: 14, Step: 1770, Loss: 0.398765\n",
      "Epoch: 14, Step: 1780, Loss: 0.616922\n",
      "Epoch: 14, Step: 1790, Loss: 0.546991\n",
      "Epoch: 14, Step: 1800, Loss: 0.184701\n",
      "Epoch: 14, Step: 1810, Loss: 0.381223\n",
      "Epoch: 14, Step: 1820, Loss: 0.313479\n",
      "Epoch: 14, Step: 1830, Loss: 0.393621\n",
      "Epoch: 14, Step: 1840, Loss: 0.181132\n",
      "Epoch: 14, Step: 1850, Loss: 0.380754\n",
      "Epoch: 15, Step: 1500, Loss: 0.423129\n",
      "Epoch: 15, Step: 1510, Loss: 0.404926\n",
      "Epoch: 15, Step: 1520, Loss: 0.313784\n",
      "Epoch: 15, Step: 1530, Loss: 0.139606\n",
      "Epoch: 15, Step: 1540, Loss: 0.234506\n",
      "Epoch: 15, Step: 1550, Loss: 0.248689\n",
      "Epoch: 15, Step: 1560, Loss: 0.159241\n",
      "Epoch: 15, Step: 1570, Loss: 0.146279\n",
      "Epoch: 15, Step: 1580, Loss: 0.213513\n",
      "Epoch: 15, Step: 1590, Loss: 0.32425\n",
      "Epoch: 15, Step: 1600, Loss: 0.241899\n",
      "Epoch: 15, Step: 1610, Loss: 0.239279\n",
      "Epoch: 15, Step: 1620, Loss: 0.172731\n",
      "Epoch: 15, Step: 1630, Loss: 0.329817\n",
      "Epoch: 15, Step: 1640, Loss: 0.193906\n",
      "Epoch: 15, Step: 1650, Loss: 0.369424\n",
      "Epoch: 15, Step: 1660, Loss: 0.473888\n",
      "Epoch: 15, Step: 1670, Loss: 0.205665\n",
      "Epoch: 15, Step: 1680, Loss: 0.106464\n",
      "Epoch: 15, Step: 1690, Loss: 0.213829\n",
      "Epoch: 15, Step: 1700, Loss: 0.217854\n",
      "Epoch: 15, Step: 1710, Loss: 0.192937\n",
      "Epoch: 15, Step: 1720, Loss: 0.306617\n",
      "Epoch: 15, Step: 1730, Loss: 0.35901\n",
      "Epoch: 15, Step: 1740, Loss: 0.234904\n",
      "Epoch: 15, Step: 1750, Loss: 0.282517\n",
      "Epoch: 15, Step: 1760, Loss: 0.226592\n",
      "Epoch: 15, Step: 1770, Loss: 0.190517\n",
      "Epoch: 15, Step: 1780, Loss: 0.162187\n",
      "Epoch: 15, Step: 1790, Loss: 0.43064\n",
      "Epoch: 15, Step: 1800, Loss: 0.406433\n",
      "Epoch: 15, Step: 1810, Loss: 0.978222\n",
      "Epoch: 15, Step: 1820, Loss: 0.293316\n",
      "Epoch: 15, Step: 1830, Loss: 0.242598\n",
      "Epoch: 15, Step: 1840, Loss: 0.171801\n",
      "Epoch: 15, Step: 1850, Loss: 0.87581\n",
      "Epoch: 15, Step: 1860, Loss: 0.171393\n",
      "Epoch: 15, Step: 1870, Loss: 0.09987\n",
      "Epoch: 15, Step: 1880, Loss: 0.455375\n",
      "Epoch: 15, Step: 1890, Loss: 0.340069\n",
      "Epoch: 15, Step: 1900, Loss: 0.495589\n",
      "Epoch: 15, Step: 1910, Loss: 0.0765503\n",
      "Epoch: 15, Step: 1920, Loss: 0.456905\n",
      "Epoch: 15, Step: 1930, Loss: 0.203476\n",
      "Epoch: 15, Step: 1940, Loss: 0.215296\n",
      "Epoch: 15, Step: 1950, Loss: 0.396094\n",
      "Epoch: 16, Step: 1600, Loss: 0.278189\n",
      "Epoch: 16, Step: 1610, Loss: 0.339155\n",
      "Epoch: 16, Step: 1620, Loss: 0.17439\n",
      "Epoch: 16, Step: 1630, Loss: 0.375011\n",
      "Epoch: 16, Step: 1640, Loss: 0.134843\n",
      "Epoch: 16, Step: 1650, Loss: 0.225139\n",
      "Epoch: 16, Step: 1660, Loss: 0.441484\n",
      "Epoch: 16, Step: 1670, Loss: 0.358309\n",
      "Epoch: 16, Step: 1680, Loss: 0.305857\n",
      "Epoch: 16, Step: 1690, Loss: 0.339469\n",
      "Epoch: 16, Step: 1700, Loss: 0.308815\n",
      "Epoch: 16, Step: 1710, Loss: 0.149611\n",
      "Epoch: 16, Step: 1720, Loss: 0.363111\n",
      "Epoch: 16, Step: 1730, Loss: 0.74223\n",
      "Epoch: 16, Step: 1740, Loss: 0.324452\n",
      "Epoch: 16, Step: 1750, Loss: 0.556714\n",
      "Epoch: 16, Step: 1760, Loss: 0.143367\n",
      "Epoch: 16, Step: 1770, Loss: 0.213376\n",
      "Epoch: 16, Step: 1780, Loss: 0.437191\n",
      "Epoch: 16, Step: 1790, Loss: 0.168222\n",
      "Epoch: 16, Step: 1800, Loss: 0.160436\n",
      "Epoch: 16, Step: 1810, Loss: 0.410198\n",
      "Epoch: 16, Step: 1820, Loss: 0.147114\n",
      "Epoch: 16, Step: 1830, Loss: 0.158243\n",
      "Epoch: 16, Step: 1840, Loss: 0.551257\n",
      "Epoch: 16, Step: 1850, Loss: 0.236566\n",
      "Epoch: 16, Step: 1860, Loss: 0.194531\n",
      "Epoch: 16, Step: 1870, Loss: 0.230402\n",
      "Epoch: 16, Step: 1880, Loss: 0.218222\n",
      "Epoch: 16, Step: 1890, Loss: 0.254836\n",
      "Epoch: 16, Step: 1900, Loss: 0.0987947\n",
      "Epoch: 16, Step: 1910, Loss: 0.171433\n",
      "Epoch: 16, Step: 1920, Loss: 0.127094\n",
      "Epoch: 16, Step: 1930, Loss: 0.237426\n",
      "Epoch: 16, Step: 1940, Loss: 0.204293\n",
      "Epoch: 16, Step: 1950, Loss: 0.453495\n",
      "Epoch: 16, Step: 1960, Loss: 0.384734\n",
      "Epoch: 16, Step: 1970, Loss: 0.569536\n",
      "Epoch: 16, Step: 1980, Loss: 0.481818\n",
      "Epoch: 16, Step: 1990, Loss: 0.169813\n",
      "Epoch: 16, Step: 2000, Loss: 0.466841\n",
      "Epoch: 16, Step: 2010, Loss: 0.19163\n",
      "Epoch: 16, Step: 2020, Loss: 0.379437\n",
      "Epoch: 16, Step: 2030, Loss: 0.201711\n",
      "Epoch: 16, Step: 2040, Loss: 0.37086\n",
      "Epoch: 16, Step: 2050, Loss: 0.405937\n",
      "Epoch: 17, Step: 1700, Loss: 0.406097\n",
      "Epoch: 17, Step: 1710, Loss: 0.327453\n",
      "Epoch: 17, Step: 1720, Loss: 0.159106\n",
      "Epoch: 17, Step: 1730, Loss: 0.247339\n",
      "Epoch: 17, Step: 1740, Loss: 0.202475\n",
      "Epoch: 17, Step: 1750, Loss: 0.120151\n",
      "Epoch: 17, Step: 1760, Loss: 0.18088\n",
      "Epoch: 17, Step: 1770, Loss: 0.25505\n",
      "Epoch: 17, Step: 1780, Loss: 0.260855\n",
      "Epoch: 17, Step: 1790, Loss: 0.204381\n",
      "Epoch: 17, Step: 1800, Loss: 0.295417\n",
      "Epoch: 17, Step: 1810, Loss: 0.270539\n",
      "Epoch: 17, Step: 1820, Loss: 0.172897\n",
      "Epoch: 17, Step: 1830, Loss: 0.336543\n",
      "Epoch: 17, Step: 1840, Loss: 0.259098\n",
      "Epoch: 17, Step: 1850, Loss: 0.414376\n",
      "Epoch: 17, Step: 1860, Loss: 0.201865\n",
      "Epoch: 17, Step: 1870, Loss: 0.113328\n",
      "Epoch: 17, Step: 1880, Loss: 0.322007\n",
      "Epoch: 17, Step: 1890, Loss: 0.110842\n",
      "Epoch: 17, Step: 1900, Loss: 0.221228\n",
      "Epoch: 17, Step: 1910, Loss: 0.252693\n",
      "Epoch: 17, Step: 1920, Loss: 0.363635\n",
      "Epoch: 17, Step: 1930, Loss: 0.221803\n",
      "Epoch: 17, Step: 1940, Loss: 0.279561\n",
      "Epoch: 17, Step: 1950, Loss: 0.278295\n",
      "Epoch: 17, Step: 1960, Loss: 0.159093\n",
      "Epoch: 17, Step: 1970, Loss: 0.136311\n",
      "Epoch: 17, Step: 1980, Loss: 0.427997\n",
      "Epoch: 17, Step: 1990, Loss: 0.429381\n",
      "Epoch: 17, Step: 2000, Loss: 1.06277\n",
      "Epoch: 17, Step: 2010, Loss: 0.232816\n",
      "Epoch: 17, Step: 2020, Loss: 0.180248\n",
      "Epoch: 17, Step: 2030, Loss: 0.163421\n",
      "Epoch: 17, Step: 2040, Loss: 0.881622\n",
      "Epoch: 17, Step: 2050, Loss: 0.160305\n",
      "Epoch: 17, Step: 2060, Loss: 0.100859\n",
      "Epoch: 17, Step: 2070, Loss: 0.589245\n",
      "Epoch: 17, Step: 2080, Loss: 0.317576\n",
      "Epoch: 17, Step: 2090, Loss: 0.350099\n",
      "Epoch: 17, Step: 2100, Loss: 0.134805\n",
      "Epoch: 17, Step: 2110, Loss: 0.452772\n",
      "Epoch: 17, Step: 2120, Loss: 0.148028\n",
      "Epoch: 17, Step: 2130, Loss: 0.273565\n",
      "Epoch: 17, Step: 2140, Loss: 0.359827\n",
      "Epoch: 17, Step: 2150, Loss: 0.396833\n",
      "Epoch: 18, Step: 1800, Loss: 0.182648\n",
      "Epoch: 18, Step: 1810, Loss: 0.307689\n",
      "Epoch: 18, Step: 1820, Loss: 0.226994\n",
      "Epoch: 18, Step: 1830, Loss: 0.162945\n",
      "Epoch: 18, Step: 1840, Loss: 0.196704\n",
      "Epoch: 18, Step: 1850, Loss: 0.430491\n",
      "Epoch: 18, Step: 1860, Loss: 0.376553\n",
      "Epoch: 18, Step: 1870, Loss: 0.473838\n",
      "Epoch: 18, Step: 1880, Loss: 0.338253\n",
      "Epoch: 18, Step: 1890, Loss: 0.109097\n",
      "Epoch: 18, Step: 1900, Loss: 0.151171\n",
      "Epoch: 18, Step: 1910, Loss: 0.434793\n",
      "Epoch: 18, Step: 1920, Loss: 0.767059\n",
      "Epoch: 18, Step: 1930, Loss: 0.347087\n",
      "Epoch: 18, Step: 1940, Loss: 0.420385\n",
      "Epoch: 18, Step: 1950, Loss: 0.162709\n",
      "Epoch: 18, Step: 1960, Loss: 0.216979\n",
      "Epoch: 18, Step: 1970, Loss: 0.429527\n",
      "Epoch: 18, Step: 1980, Loss: 0.209494\n",
      "Epoch: 18, Step: 1990, Loss: 0.115282\n",
      "Epoch: 18, Step: 2000, Loss: 0.393078\n",
      "Epoch: 18, Step: 2010, Loss: 0.160567\n",
      "Epoch: 18, Step: 2020, Loss: 0.467683\n",
      "Epoch: 18, Step: 2030, Loss: 0.211963\n",
      "Epoch: 18, Step: 2040, Loss: 0.298097\n",
      "Epoch: 18, Step: 2050, Loss: 0.146348\n",
      "Epoch: 18, Step: 2060, Loss: 0.241265\n",
      "Epoch: 18, Step: 2070, Loss: 0.183911\n",
      "Epoch: 18, Step: 2080, Loss: 0.249837\n",
      "Epoch: 18, Step: 2090, Loss: 0.129089\n",
      "Epoch: 18, Step: 2100, Loss: 0.145765\n",
      "Epoch: 18, Step: 2110, Loss: 0.226374\n",
      "Epoch: 18, Step: 2120, Loss: 0.13213\n",
      "Epoch: 18, Step: 2130, Loss: 0.308245\n",
      "Epoch: 18, Step: 2140, Loss: 0.35092\n",
      "Epoch: 18, Step: 2150, Loss: 0.596913\n",
      "Epoch: 18, Step: 2160, Loss: 0.36932\n",
      "Epoch: 18, Step: 2170, Loss: 0.499489\n",
      "Epoch: 18, Step: 2180, Loss: 0.189175\n",
      "Epoch: 18, Step: 2190, Loss: 0.442214\n",
      "Epoch: 18, Step: 2200, Loss: 0.231301\n",
      "Epoch: 18, Step: 2210, Loss: 0.31814\n",
      "Epoch: 18, Step: 2220, Loss: 0.275046\n",
      "Epoch: 18, Step: 2230, Loss: 0.298665\n",
      "Epoch: 18, Step: 2240, Loss: 0.633477\n",
      "Epoch: 18, Step: 2250, Loss: 0.14677\n",
      "Epoch: 19, Step: 1900, Loss: 0.32118\n",
      "Epoch: 19, Step: 1910, Loss: 0.152174\n",
      "Epoch: 19, Step: 1920, Loss: 0.255042\n",
      "Epoch: 19, Step: 1930, Loss: 0.211217\n",
      "Epoch: 19, Step: 1940, Loss: 0.109078\n",
      "Epoch: 19, Step: 1950, Loss: 0.27212\n",
      "Epoch: 19, Step: 1960, Loss: 0.284237\n",
      "Epoch: 19, Step: 1970, Loss: 0.14646\n",
      "Epoch: 19, Step: 1980, Loss: 0.206714\n",
      "Epoch: 19, Step: 1990, Loss: 0.282162\n",
      "Epoch: 19, Step: 2000, Loss: 0.255988\n",
      "Epoch: 19, Step: 2010, Loss: 0.193679\n",
      "Epoch: 19, Step: 2020, Loss: 0.421407\n",
      "Epoch: 19, Step: 2030, Loss: 0.296758\n",
      "Epoch: 19, Step: 2040, Loss: 0.367521\n",
      "Epoch: 19, Step: 2050, Loss: 0.0993065\n",
      "Epoch: 19, Step: 2060, Loss: 0.108463\n",
      "Epoch: 19, Step: 2070, Loss: 0.326904\n",
      "Epoch: 19, Step: 2080, Loss: 0.116607\n",
      "Epoch: 19, Step: 2090, Loss: 0.220315\n",
      "Epoch: 19, Step: 2100, Loss: 0.240908\n",
      "Epoch: 19, Step: 2110, Loss: 0.356127\n",
      "Epoch: 19, Step: 2120, Loss: 0.239319\n",
      "Epoch: 19, Step: 2130, Loss: 0.284706\n",
      "Epoch: 19, Step: 2140, Loss: 0.246465\n",
      "Epoch: 19, Step: 2150, Loss: 0.152434\n",
      "Epoch: 19, Step: 2160, Loss: 0.136965\n",
      "Epoch: 19, Step: 2170, Loss: 0.449596\n",
      "Epoch: 19, Step: 2180, Loss: 0.434222\n",
      "Epoch: 19, Step: 2190, Loss: 1.03382\n",
      "Epoch: 19, Step: 2200, Loss: 0.298399\n",
      "Epoch: 19, Step: 2210, Loss: 0.186005\n",
      "Epoch: 19, Step: 2220, Loss: 0.0963956\n",
      "Epoch: 19, Step: 2230, Loss: 0.875251\n",
      "Epoch: 19, Step: 2240, Loss: 0.152993\n",
      "Epoch: 19, Step: 2250, Loss: 0.279032\n",
      "Epoch: 19, Step: 2260, Loss: 0.419593\n",
      "Epoch: 19, Step: 2270, Loss: 0.339247\n",
      "Epoch: 19, Step: 2280, Loss: 0.327304\n",
      "Epoch: 19, Step: 2290, Loss: 0.180528\n",
      "Epoch: 19, Step: 2300, Loss: 0.416051\n",
      "Epoch: 19, Step: 2310, Loss: 0.145256\n",
      "Epoch: 19, Step: 2320, Loss: 0.275031\n",
      "Epoch: 19, Step: 2330, Loss: 0.365038\n",
      "Epoch: 19, Step: 2340, Loss: 0.385926\n",
      "Epoch: 19, Step: 2350, Loss: 0.211127\n",
      "Model saved in file: ./save\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(driving_data_new.num_images / batch_size)):\n",
    "        xs, ys = driving_data_new.LoadTrainBatch(batch_size)\n",
    "        train_step.run(feed_dict={model.x: xs, model.y_: ys, model.keep_prob: 0.8})\n",
    "        if i % 10 == 0:\n",
    "            xs, ys = driving_data_new.LoadValBatch(batch_size)\n",
    "            loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "            print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "        summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "        summary_writer.add_summary(summary, epoch * driving_data_new.num_images / batch_size + i)\n",
    "\n",
    "        if i % batch_size == 0:\n",
    "            if not os.path.exists(LOGDIR):\n",
    "                os.makedirs(LOGDIR)\n",
    "            checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "            filename = saver.save(sess, checkpoint_path)\n",
    "print(\"Model saved in file: %s\" % filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa135e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command line:\n",
      "--> tensorboard --logdir=./logs \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "print(\"Run the command line:\\n\" \\\n",
    "      \"--> tensorboard --logdir=./logs \" \\\n",
    "      \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c09509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
